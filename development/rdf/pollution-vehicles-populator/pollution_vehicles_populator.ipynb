{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Pollution Vehicles Populator**"],"metadata":{"id":"X5Ilx5vB_lj-"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lIBupZyT_dpj","outputId":"32c1ef6b-39f1-4683-dd34-004183f86e4c","executionInfo":{"status":"ok","timestamp":1733848314233,"user_tz":-60,"elapsed":6005,"user":{"displayName":"Francesco Chemello","userId":"10685639817067927641"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rdflib in /usr/local/lib/python3.10/dist-packages (7.1.1)\n","Requirement already satisfied: isodate<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from rdflib) (0.7.2)\n","Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib) (3.2.0)\n"]}],"source":["pip install rdflib\n"]},{"cell_type":"code","source":["pip install datetime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mb86ZFPHAO07","outputId":"dd10f689-01c0-43a6-d2d6-aa1dc78ba614","executionInfo":{"status":"ok","timestamp":1733848322554,"user_tz":-60,"elapsed":8326,"user":{"displayName":"Francesco Chemello","userId":"10685639817067927641"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datetime in /usr/local/lib/python3.10/dist-packages (5.5)\n","Requirement already satisfied: zope.interface in /usr/local/lib/python3.10/dist-packages (from datetime) (7.2)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from datetime) (2024.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->datetime) (75.1.0)\n"]}]},{"cell_type":"code","source":["pip install tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WyuiYQzZASPX","outputId":"1d15e50b-d1b1-41f1-bcb1-95db8f663414","executionInfo":{"status":"ok","timestamp":1733848328227,"user_tz":-60,"elapsed":5678,"user":{"displayName":"Francesco Chemello","userId":"10685639817067927641"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"]}]},{"cell_type":"code","source":["pip install psutil"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"imRHuIOSQsC8","executionInfo":{"status":"ok","timestamp":1733848336152,"user_tz":-60,"elapsed":7929,"user":{"displayName":"Francesco Chemello","userId":"10685639817067927641"}},"outputId":"6f8faa5b-fe7c-41db-ea66-9405661685e2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from tqdm import tqdm\n","import datetime\n","\n","from rdflib import Graph, Literal, RDF, RDFS, URIRef, Namespace\n","from rdflib.plugins.sparql import prepareQuery\n","from rdflib.namespace import XSD"],"metadata":{"id":"rzMpCUFg_5n_","executionInfo":{"status":"ok","timestamp":1733848337060,"user_tz":-60,"elapsed":913,"user":{"displayName":"Francesco Chemello","userId":"10685639817067927641"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# To measure the usage of RAM\n","import psutil"],"metadata":{"id":"m0vjYh4zQlEn","executionInfo":{"status":"ok","timestamp":1733848337060,"user_tz":-60,"elapsed":6,"user":{"displayName":"Francesco Chemello","userId":"10685639817067927641"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Use your personal account!\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J3F_GyAOAGXZ","outputId":"232934f9-0a23-414c-b299-a2060e6c541c","executionInfo":{"status":"ok","timestamp":1733848338617,"user_tz":-60,"elapsed":1562,"user":{"displayName":"Francesco Chemello","userId":"10685639817067927641"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["## Datasets\n","\n","# Rilevazione flusso datasets\n","rilevazione_flusso = []\n","\n","# ONLY FOR TEST\n","# rilevazione_flusso.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/test/rilevazione_flusso_veicoli_2019.csv')\n","\n","rilevazione_flusso.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/rilevazione_flusso_veicoli_2019.csv')\n","rilevazione_flusso.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/rilevazione_flusso_veicoli_2020.csv')\n","rilevazione_flusso.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/rilevazione_flusso_veicoli_2021.csv')\n","rilevazione_flusso.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/rilevazione_flusso_veicoli_2022.csv')\n","\n","# Accuratezza spire datasets\n","accuratezza_spire = []\n","\n","# ONLY FOR TEST\n","# accuratezza_spire.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/test/accuratezza_spire_2019.csv')\n","\n","accuratezza_spire.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/accuratezza_spire_2019.csv')\n","accuratezza_spire.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/accuratezza_spire_2020.csv')\n","accuratezza_spire.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/accuratezza_spire_2021.csv')\n","accuratezza_spire.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/accuratezza_spire_2022.csv')\n","\n","# Centraline qualitÃ  datasets\n","centraline = []\n","\n","# ONLY FOR TEST\n","# centraline.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/test/dati_centraline_2019.csv')\n","\n","centraline.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/dati_centraline_2019.csv')\n","centraline.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/dati_centraline_2020.csv')\n","centraline.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/dati_centraline_2021.csv')\n","centraline.append('/content/drive/MyDrive/Colab Notebooks/Graph Database/datasets/dati_centraline_2022.csv')\n","\n","# Save path\n","save_path = '/content/drive/MyDrive/Colab Notebooks/Graph Database/rdf'"],"metadata":{"id":"sfAOhJgX_8B1","executionInfo":{"status":"ok","timestamp":1733848338617,"user_tz":-60,"elapsed":6,"user":{"displayName":"Francesco Chemello","userId":"10685639817067927641"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Chunksize (aviod memory error)\n","chunksize = 500\n","\n","# Define the Namespace\n","BTP = Namespace(\"http://www.dei.unipd.it/~gdb/ontology/btp/#\")\n","\n","# Pollution coils geopoint -> from google maps!\n","viaChiarini_gp = [44.4997732567231, 11.2873095406444]\n","giardiniMargherita_gp = [44.4830615285162, 11.3528830371546] # via Medaro Bottonelli\n","portaSanFelice_gp = [44.4991470592725, 11.3270506316853]"],"metadata":{"id":"7QNzoF7LBSSs","executionInfo":{"status":"ok","timestamp":1733848338618,"user_tz":-60,"elapsed":6,"user":{"displayName":"Francesco Chemello","userId":"10685639817067927641"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# I check if the folder is empty or not\n","if not os.listdir(save_path) == []:\n","    print(\"The folder is not empty, do you want to continue? (y/n)\")\n","    answer = input()\n","    if(answer.lower() == 'y'):\n","        # I remove all the files in the folder\n","        print(\"Removing all the files in the folder ...\")\n","        for file in os.listdir(save_path):\n","            os.remove(os.path.join(save_path, file))\n","        print(\"DONE!\")\n","    else:\n","        exit()"],"metadata":{"id":"aZ31zzZCBZOs","executionInfo":{"status":"ok","timestamp":1733848338618,"user_tz":-60,"elapsed":6,"user":{"displayName":"Francesco Chemello","userId":"10685639817067927641"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(\"--- populating vehicle count and coils ---\")\n","\n","# Graphs\n","\n","# Graph for coils\n","g_coils = Graph()\n","\n","# Bind Namespaces\n","g_coils.bind(\"xsd\", XSD)\n","g_coils.bind(\"btp\", BTP)\n","\n","# Graph for vehicle count\n","g_vc = Graph()\n","\n","# Bind Namespaces\n","g_vc.bind(\"xsd\", XSD)\n","g_vc.bind(\"btp\", BTP)\n","\n","for namefile in rilevazione_flusso:\n","\n","    year_dataset = namefile.split('_')[3].split('.')[0]\n","    piece = 0\n","\n","    total_rows = len(pd.read_csv(namefile))\n","    pbar = tqdm(total=total_rows)\n","\n","    for chunk in pd.read_csv(namefile, sep=';', chunksize=chunksize):\n","\n","        for index, row in chunk.iterrows():\n","\n","            # I check if the record is valid or not -> must have all the field not NaN\n","            if row['Livello'] == '' and row['tipologia'] == '' and row['Nome via'] == '':\n","                # I skip the record -> next record\n","                continue\n","            # else: is valid -> continue\n","\n","            for i in range(2, 26):\n","\n","                ## COIL:\n","                # -uri: coil_ + id number.\n","                # -attributi: hasID\n","                # -object properties: hasLevel, hasType, isOn, and isPlacedOn.\n","\n","                ## VEHICLEDETECTION:\n","                # -uri: vehicleDetection_ + id number + _ + date.\n","                # -attributi: hasCount.\n","                # -object properties: isObserved, hasObserve, isObservedOnPeriod, and hasObservedOnPeriod.\n","\n","                date_obj = datetime.datetime.strptime(str(row['data']), '%Y-%m-%d')\n","                VehicleDetection = URIRef(BTP[\"vehicleDetection_\"+str(row['ID_univoco_stazione_spira'])+\"_\"+date_obj.strftime('%Y-%m-%d')+\"_\"+str(i-2).zfill(2)+\":00-\"+str(i-1).zfill(2)+\":00\"])\n","                g_vc.add((VehicleDetection, RDF.type, BTP.VehicleDetection))\n","\n","                # CHECK IF IT WORKS!! ##########################################\n","\n","                Coil = URIRef(BTP[\"coil_\"+str(row['ID_univoco_stazione_spira'])])\n","\n","                # PollutionCoils and SimpleCoils are subclasses of Coil\n","                g_coils.add((BTP.SimpleCoil, RDFS.subClassOf, BTP.Coil))\n","                g_coils.add((BTP.PollutionCoil, RDFS.subClassOf, BTP.Coil))\n","\n","                # Cast to float\n","                latitudine = row['latitudine']\n","                longitudine = row['longitudine']\n","\n","                if(type(latitudine) == str):\n","                    latitudine = latitudine.replace(',', '')\n","                    # From 113473933293812,00 to 11.3473933293812\n","                    latitudine = latitudine[:2] + '.' + latitudine[2:]\n","                    # Cast to float\n","                    latitudine = float(latitudine)\n","                if(type(longitudine) == str):\n","                    longitudine = longitudine.replace(',', '')\n","                    # From 44500438455000,00 to 44.500438455000\n","                    longitudine = longitudine[:2] + '.' + longitudine[2:]\n","                    longitudine = float(longitudine)\n","\n","                # Pollution coils -> must be around 300 m\n","                if ((latitudine <= viaChiarini_gp[0] + 0.0027) and (latitudine >= viaChiarini_gp[0] + 0.0027)) and ((longitudine <= viaChiarini_gp[1] + 0.0013) and (longitudine >= viaChiarini_gp[1] - 0.0013)):\n","                    g_coils.add((Coil, RDF.type, BTP.PollutionCoil))\n","                    PollutionStation = URIRef(BTP[\"controlUnitViaChiarini\"])\n","                    g_coils.add((PollutionStation, RDF.type, BTP.PollutionStation))\n","                    g_coils.add((PollutionStation, BTP.isNearTo, Coil))\n","                elif ((latitudine <= giardiniMargherita_gp[0] + 0.0027) and (latitudine >= giardiniMargherita_gp[0] + 0.0027)) and ((longitudine <= giardiniMargherita_gp[1] + 0.0013) and (longitudine >= giardiniMargherita_gp[1] - 0.0013)):\n","                    g_coils.add((Coil, RDF.type, BTP.PollutionCoil))\n","                    PollutionStation = URIRef(BTP[\"controlUnitGiardiniMargherita\"])\n","                    g_coils.add((PollutionStation, RDF.type, BTP.PollutionStation))\n","                    g_coils.add((PollutionStation, BTP.isNearTo, Coil))\n","                elif ((latitudine <= portaSanFelice_gp[0] + 0.0027) and (latitudine >= portaSanFelice_gp[0] + 0.0027)) and ((longitudine <= portaSanFelice_gp[1] + 0.0013) and (longitudine >= portaSanFelice_gp[1] - 0.0013)):\n","                    g_coils.add((Coil, RDF.type, BTP.PollutionCoil))\n","                    PollutionStation = URIRef(BTP[\"controlUnitPortaSanFelice\"])\n","                    g_coils.add((PollutionStation, RDF.type, BTP.PollutionStation))\n","                    g_coils.add((PollutionStation, BTP.isNearTo, Coil))\n","                else:\n","                    g_coils.add((Coil, RDF.type, BTP.SimpleCoil))\n","\n","                g_vc.add((VehicleDetection, BTP.isObserved, Coil))\n","                g_vc.add((Coil, BTP.hasObserve, VehicleDetection))\n","\n","                ################################################################\n","\n","                Level = URIRef(BTP[\"level_\"+str(row['Livello'])])\n","                g_coils.add((Level, RDF.type, BTP.Level))\n","                g_coils.add((Coil, BTP.hasLevel, Level))\n","\n","                Type = URIRef(BTP[\"type_\"+str(row['tipologia'])])\n","                g_coils.add((Type, RDF.type, BTP.Type))\n","                g_coils.add((Coil, BTP.hasType, Type))\n","\n","                g_coils.add((Coil, BTP.hasID, Literal(str(row['codice spira']), datatype=XSD.string)))\n","\n","                # Add the road\n","                if(row['codice via'] == ''):\n","                    continue\n","                    # MARCO's CODE\n","\n","                # Road here can't be empty\n","                Road = URIRef(BTP[\"road_\"+str(row['codice via'])])\n","                g_coils.add((Coil, BTP.isOn, Road))\n","                g_coils.add((Road, BTP.isPlacedOn, Coil))\n","                g_coils.add((Road, RDFS.label, Literal(str(row['Nome via']).lower(), datatype=XSD.string)))\n","\n","                g_vc.add((VehicleDetection, BTP.hasCount, Literal(row.iloc[i], datatype=XSD.integer)))\n","\n","                # # PERIOD:\n","                # -uri: period_ + date + _ + hour1 + _ + hour2.\n","                # -attributi: startTime and endTime.\n","                # -object properties: onDay.\n","\n","                date_obj = datetime.datetime.strptime(str(row['data']), '%Y-%m-%d')\n","                Period = URIRef(BTP[\"period_\"+date_obj.strftime('%Y-%m-%d')+\"_\"+str(i-2).zfill(2)+\":00-\"+str(i-1).zfill(2)+\":00\"])\n","                g_vc.add((Period, RDF.type, BTP.Period))\n","\n","                g_vc.add((Period, BTP.isObservedOnPeriod, VehicleDetection))\n","                g_vc.add((VehicleDetection, BTP.hasObservedOnPeriod, Period))\n","\n","                startTime = str(i-2).zfill(2)+\":00\"\n","                date_obj = datetime.datetime.strptime(str(row['data']), '%Y-%m-%d')\n","\n","                g_vc.add((Period, BTP.startTime, Literal(date_obj.strftime('%Y-%m-%d')+\"T\"+startTime, datatype=XSD.dateTime)))\n","\n","                endTime = str(i-1).zfill(2)+\":00\"\n","\n","                # If the endTime is 24 -> date+1 and endTime = 00\n","                if(endTime == '24:00'):\n","                    endTime = '00:00'\n","                    # I add one day\n","                    date_obj = date_obj + datetime.timedelta(days=1)\n","\n","                g_vc.add((Period, BTP.endTime, Literal(date_obj.strftime('%Y-%m-%d')+\"T\"+endTime, datatype=XSD.dateTime)))\n","\n","                ## Convert day from italian to english ex: lunedÃ¬ -> monday\n","                day_value = ''\n","                if 'Giorno della settimana' in row:\n","                    day_value = str(row['Giorno della settimana']).lower()\n","                elif 'giorno della settimana' in row:\n","                    day_value = str(row['giorno della settimana']).lower()\n","\n","                match day_value:\n","                    case 'lunedÃ¬':\n","                        DayWeek = URIRef(BTP[\"Monday\"])\n","                        g_vc.add((DayWeek, RDF.type, BTP.DayWeek))\n","                        g_vc.add((Period, BTP.onDay, DayWeek))\n","                    case 'martedÃ¬':\n","                        DayWeek = URIRef(BTP[\"Tuesday\"])\n","                        g_vc.add((DayWeek, RDF.type, BTP.DayWeek))\n","                        g_vc.add((Period, BTP.onDay, DayWeek))\n","                    case 'mercoledÃ¬':\n","                        DayWeek = URIRef(BTP[\"Wednesday\"])\n","                        g_vc.add((DayWeek, RDF.type, BTP.DayWeek))\n","                        g_vc.add((Period, BTP.onDay, DayWeek))\n","                    case 'giovedÃ¬':\n","                        DayWeek = URIRef(BTP[\"Thursday\"])\n","                        g_vc.add((DayWeek, RDF.type, BTP.DayWeek))\n","                        g_vc.add((Period, BTP.onDay, DayWeek))\n","                    case 'venerdÃ¬':\n","                        DayWeek = URIRef(BTP[\"Friday\"])\n","                        g_vc.add((DayWeek, RDF.type, BTP.DayWeek))\n","                        g_vc.add((Period, BTP.onDay, DayWeek))\n","                    case 'sabato':\n","                        DayWeek = URIRef(BTP[\"Saturday\"])\n","                        g_vc.add((DayWeek, RDF.type, BTP.DayWeek))\n","                        g_vc.add((Period, BTP.onDay, DayWeek))\n","                    case 'domenica':\n","                        DayWeek = URIRef(BTP[\"Sunday\"])\n","                        g_vc.add((DayWeek, RDF.type, BTP.DayWeek))\n","                        g_vc.add((Period, BTP.onDay, DayWeek))\n","                    case _:\n","                        # No day provided\n","                        pass\n","        pbar.update(chunksize)\n","\n","        # Memory monitor\n","        if psutil.virtual_memory().percent > 80:\n","          # I'm using more than 80% of the whole RAM\n","          with open(save_path+'/vehicle_counted_populated_'+year_dataset+'_'+str(piece)+'.ttl', 'w') as file:\n","            file.write(g_vc.serialize(format='turtle'))\n","          # New graph\n","          g_vc = Graph()\n","          g_vc.bind(\"xsd\", XSD)\n","          g_vc.bind(\"btp\", BTP)\n","          piece += 1\n","\n","    # Save the graph before exit\n","    with open(save_path+'/vehicle_counted_populated_'+year_dataset+'_'+str(piece)+'.ttl', 'w') as file:\n","        file.write(g_vc.serialize(format='turtle'))\n","\n","    pbar.close()"],"metadata":{"id":"XEwPrakqBeAA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef89dbd9-e664-4b95-9641-1cd018ecdde9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- populating vehicle count and coils ---\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|ââ        | 61000/287747 [21:32<1:18:10, 48.34it/s]"]}]},{"cell_type":"code","source":["# Save the graph\n","with open(save_path+'/coils_populated.ttl', 'w') as file2:\n","    file2.write(g_coils.serialize(format='turtle'))"],"metadata":{"id":"DG4n35WNBfgS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Free memory\n","del g_coils, g_vc"],"metadata":{"id":"-r1uf4VABjFf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"--- populating vehicle accuracy ---\")\n","\n","# Graphs\n","\n","# Graph for vehicle count\n","g_acc = Graph()\n","\n","# Bind Namespaces\n","g_acc.bind(\"xsd\", XSD)\n","g_acc.bind(\"btp\", BTP)\n","\n","# Load coils dataset\n","g_coils = Graph()\n","g_coils.bind(\"xsd\", XSD)\n","g_coils.parse(os.path.join(save_path, 'coils_populated.ttl'), format='turtle')\n","\n","\n","# FOR TEST TRY TO USE THE COILS DATASET!!\n","# g_coils.parse(os.path.join(save_path, 'spire_populated.ttl'), format='turtle')\n","\n","\n","# Query to get the coil's code associated to an ID (input: ID)\n","code_coil_query = prepareQuery(\"\"\"\n","    SELECT DISTINCT ?coil WHERE {\n","        ?coil btp:hasID ?id .\n","    FILTER (?id = ?coil_id)\n","                               }\"\"\" , initNs={\"btp\": BTP})\n","\n","for namefile in accuratezza_spire:\n","\n","    year_dataset = namefile.split('/')[-1].split('_')[2].split('.')[0]\n","    piece = 0\n","\n","    total_rows = len(pd.read_csv(namefile))\n","    pbar = tqdm(total=total_rows)\n","\n","    for chunk in pd.read_csv(namefile, sep=';', chunksize=chunksize):\n","\n","        for index, row in chunk.iterrows():\n","\n","            for i in range(2, 26):\n","\n","                ## VEHICLEDETECTION:\n","                # -uri: vehicleDetection_ + id number + _ + date.\n","                # -attributi: hasAccuracy, and hasCount.\n","\n","                coil = ''\n","\n","                # Query to get the coil's code associated to an ID\n","                res = g_coils.query(code_coil_query, initBindings={'coil_id':Literal(row['codice spira'], datatype=XSD.string)})\n","                if res == [] or res == None:\n","                    # I skip the record -> next record\n","                    continue\n","                else:\n","                    for r in res:\n","                        coil = str(r.coil).replace('http://www.dei.unipd.it/~gdb/ontology/btp/#coil_', '')\n","                        # It must be one!\n","                        break\n","\n","                date_obj = datetime.datetime.strptime(str(row['data']), '%Y-%m-%d')\n","\n","                VehicleDetection = URIRef(BTP[\"vehicleDetection_\"+coil+\"_\"+date_obj.strftime('%Y-%m-%d')+\"_\"+str(i-2).zfill(2)+\":00-\"+str(i-1).zfill(2)+\":00\"])\n","                g_acc.add((VehicleDetection, RDF.type, BTP.VehicleDetection))\n","                percentage = row.iloc[i].replace('%', '')\n","                g_acc.add((VehicleDetection, BTP.hasAccuracy, Literal(float(percentage), datatype=XSD.float)))\n","\n","                # # PERIOD:\n","                # -uri: period_ + date + _ + hour1 + _ + hour2.\n","                # -attributi: startTime and endTime.\n","                # -object properties: onDay.\n","\n","                Period = URIRef(BTP[\"period_\"+date_obj.strftime('%Y-%m-%d')+\"_\"+str(i-2).zfill(2)+\":00-\"+str(i-1).zfill(2)+\":00\"])\n","                g_acc.add((Period, RDF.type, BTP.Period))\n","\n","                g_acc.add((Period, BTP.isObservedOnPeriod, VehicleDetection))\n","                g_acc.add((VehicleDetection, BTP.hasObservedOnPeriod, Period))\n","\n","                startTime = str(i-2).zfill(2)+\":00\"\n","                date_obj = datetime.datetime.strptime(str(row['data']), '%Y-%m-%d')\n","\n","                g_acc.add((Period, BTP.startTime, Literal(date_obj.strftime('%Y-%m-%d')+\"T\"+startTime, datatype=XSD.dateTime)))\n","\n","                endTime = str(i-1).zfill(2)+\":00\"\n","\n","                # If the endTime is 24 -> date+1 and endTime = 00\n","                if(endTime == '24:00'):\n","                    endTime = '00:00'\n","                    # I add one day\n","                    date_obj = date_obj + datetime.timedelta(days=1)\n","\n","                g_acc.add((Period, BTP.endTime, Literal(date_obj.strftime('%Y-%m-%d')+\"T\"+endTime, datatype=XSD.dateTime)))\n","\n","        pbar.update(chunksize)\n","\n","        # Memory monitor\n","        if psutil.virtual_memory().percent > 80:\n","          # I'm using more than 80% of the whole RAM\n","          with open(save_path+'/vehicle_accuracy_populated_'+year_dataset+'_'+str(piece)+'.ttl', 'w') as file:\n","            file.write(g_vc.serialize(format='turtle'))\n","          # New graph\n","          g_vc = Graph()\n","          g_vc.bind(\"xsd\", XSD)\n","          g_vc.bind(\"btp\", BTP)\n","          piece += 1\n","\n","    # Save the graph before exit\n","    with open(save_path+'/vehicle_accuracy_populated_'+year_dataset+'_'+str(piece)+'.ttl', 'w') as file:\n","        file.write(g_vc.serialize(format='turtle'))\n","\n","    pbar.close()"],"metadata":{"id":"jzahuoyABmae"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Free memory\n","del g_acc, g_coils"],"metadata":{"id":"VaLLV0NCBxCl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"--- populating pollution data ---\")\n","\n","# Graphs\n","\n","# Graph for vehicle count\n","g_pol = Graph()\n","\n","# Bind Namespaces\n","g_pol.bind(\"xsd\", XSD)\n","g_pol.bind(\"btp\", BTP)\n","\n","for namefile in centraline:\n","\n","    year_dataset = namefile.split('/')[-1].split('_')[2].split('.')[0]\n","    piece = 0\n","\n","    total_rows = len(pd.read_csv(namefile))\n","    pbar = tqdm(total=total_rows)\n","\n","    for chunk in pd.read_csv(namefile, sep=';', chunksize=chunksize):\n","\n","        for index, row in chunk.iterrows():\n","\n","            ## POLLUTIONSTATION:\n","            # -uri: centralUnit + pollution name.\n","            # -object properties: hasRegister, and isRegistered.\n","\n","            PollutionStation = URIRef(BTP[\"controlUnit\" + (str(row['COD_STAZ']).lower()).replace(\" \", \"\")])\n","            g_pol.add((PollutionStation, RDF.type, BTP.PollutionStation))\n","\n","            # PERIOD:\n","            # -uri: period_ + date + _ + hour1 + _ + hour2.\n","            # -attributi: startTime and endTime.\n","            # -object properties: onDay.\n","\n","            # date format: yyyy-mm-ddThh:mm:ss+hh:mm\n","            # keep only the data: 'Thh:mm:ss+hh:mm' -> yyyy-mm-dd\n","            date_obj = datetime.datetime.strptime((str(row['DATA_INIZIO']).split('T'))[0], '%Y-%m-%d')\n","            # keep only the hour: 'Thh:mm:ss+hh:mm' -> hh:mm:ss\n","            startTime = str((((str(row['DATA_INIZIO']).split('T'))[1].split('+')[0]).split(':'))[0])+\":00\"\n","            endTime = str((((str(row['DATA_FINE']).split('T'))[1].split('+')[0]).split(':'))[0])+\":00\"\n","            Period = URIRef(BTP[\"period_\"+date_obj.strftime('%Y-%m-%d')+\"_\"+startTime+\"-\"+endTime])\n","\n","            g_pol.add((Period, RDF.type, BTP.Period))\n","            g_pol.add((Period, BTP.startTime, Literal(date_obj.strftime('%Y-%m-%d')+\"T\"+startTime, datatype=XSD.dateTime)))\n","            g_pol.add((Period, BTP.endTime, Literal(date_obj.strftime('%Y-%m-%d')+\"T\"+endTime, datatype=XSD.dateTime)))\n","\n","            ## CHEMICALDETECTION:\n","            # -uri: chemicalDetection_ + pollution_station_name + _ + date + _ + element.\n","            # -attributi: inQuantity (conversion all in ug/m), and hasChemicalName.\n","            # -object properties: isDetectedOnPeriod, hasDetectedOnPeriod, hasDetect, and isDetected.\n","\n","            chemical_element = (row['AGENTE'].split(\"(\")[0]).strip()\n","            ChemicalElement = URIRef(BTP[\"chemicalElement_\"+chemical_element])\n","\n","            date_obj = datetime.datetime.strptime((str(row['DATA_INIZIO']).split('T'))[0], '%Y-%m-%d')\n","            ChemicalDetection = URIRef(BTP[\"chemicalDetection_\"+(str(row['COD_STAZ']).lower()).replace(\" \", \"\")+\"_\"+date_obj.strftime('%Y-%m-%d')+\"_\"+startTime+\"-\"+endTime+\"_\"+chemical_element])\n","            g_pol.add((ChemicalDetection, RDF.type, BTP.ChemicalDetection))\n","\n","            # Cast from mg/m^3 to ug/m^3\n","            if(row['UM'] == 'mg/m3'):\n","                g_pol.add((ChemicalDetection, BTP.inQuantity, Literal((row['VALORE']*1000), datatype=XSD.float)))\n","            else:\n","                g_pol.add((ChemicalDetection, BTP.inQuantity, Literal((row['VALORE']), datatype=XSD.float)))\n","\n","            ## CHEMICALELEMENT:\n","            # -uri: chemicalElement_ + chemical element name.\n","            # -object properties: hasDetect, and isDetected\n","\n","            g_pol.add((ChemicalElement, RDF.type, BTP.ChemicalElement))\n","            g_pol.add((ChemicalDetection, BTP.hasDetect, ChemicalElement))\n","            g_pol.add((ChemicalElement, BTP.isDetected, ChemicalDetection))\n","\n","            if len(row['AGENTE'].split(\"(\")) > 1:\n","                chemical_element_name = (((row['AGENTE'].split(\"(\")[1]).replace(\")\",\"\")).strip()).lower()\n","\n","                match chemical_element_name:\n","                    case 'benzene':\n","                        g_pol.add((ChemicalDetection, BTP.hasChemicalName, Literal(\"Benzene\", datatype=XSD.string)))\n","                    case 'monossido di carbonio':\n","                        g_pol.add((ChemicalDetection, BTP.hasChemicalName, Literal(\"Carbon monoxide\", datatype=XSD.string)))\n","                    case 'monossido di azoto':\n","                        g_pol.add((ChemicalDetection, BTP.hasChemicalName, Literal(\"Nitrogen Monoxide\", datatype=XSD.string)))\n","                    case 'biossido di azoto':\n","                        g_pol.add((ChemicalDetection, BTP.hasChemicalName, Literal(\"Nitrogen dioxide\", datatype=XSD.string)))\n","                    case 'ossidi di azoto':\n","                        g_pol.add((ChemicalDetection, BTP.hasChemicalName, Literal(\"Nitrogen oxides\", datatype=XSD.string)))\n","                    case 'ozono':\n","                        g_pol.add((ChemicalDetection, BTP.hasChemicalName, Literal(\"Ozone\", datatype=XSD.string)))\n","                    case _:\n","                        # New element provided\n","                        g_pol.add((ChemicalDetection, BTP.hasChemicalName, Literal(chemical_element_name, datatype=XSD.string)))\n","\n","        pbar.update(chunksize)\n","\n","        # Memory monitor\n","        if psutil.virtual_memory().percent > 80:\n","          # I'm using more than 80% of the whole RAM\n","          with open(save_path+'/pollution_data_populated_'+year_dataset+'_'+str(piece)+'.ttl', 'w') as file:\n","            file.write(g_vc.serialize(format='turtle'))\n","          # New graph\n","          g_vc = Graph()\n","          g_vc.bind(\"xsd\", XSD)\n","          g_vc.bind(\"btp\", BTP)\n","          piece += 1\n","\n","    # Save the graph before exit\n","    with open(save_path+'/pollution_data_populated_'+year_dataset+'_'+str(piece)+'.ttl', 'w') as file:\n","        file.write(g_vc.serialize(format='turtle'))\n","\n","    pbar.close()"],"metadata":{"id":"aj-HzvIKBzRk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the graph\n","with open (save_path+'/pollution_data_populated.ttl', 'a') as file:\n","    file.write(g_pol.serialize(format='turtle'))"],"metadata":{"id":"CgSwPtz6B4p1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Free memory\n","del g_pol"],"metadata":{"id":"bC1em3j_B5rH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"--- end ---\")"],"metadata":{"id":"mFyRldbxB8sL"},"execution_count":null,"outputs":[]}]}